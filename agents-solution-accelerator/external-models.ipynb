{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc63c705-cfb6-4dad-946a-c76d201f371d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Enable Databricks Mosaic AI Gateway features\n",
    "\n",
    "This notebook shows how to enable and use Databricks Mosaic AI Gateway features to manage and govern models from providers, such as OpenAI and Anthropic. \n",
    "\n",
    "In this notebook, you use the Model Serving and AI Gateway API to accomplish the following tasks:\n",
    "\n",
    "- Create and configure an endpoint for OpenAI GPT-4o-Mini.\n",
    "- Enable AI Gateway features including usage tracking, inference tables, guardrails, and rate limits. \n",
    "- Set up invalid keywords and personally identifiable information (PII) detection for model requests and responses.\n",
    "- Implement rate limits for model serving endpoints.\n",
    "- Configure multiple models for A/B testing.\n",
    "- Enable fallbacks for failed requests.\n",
    "\n",
    "If you prefer a low-code experience, you can create an external models endpoint and configure AI Gateway features using the Serving UI ([AWS](https://docs.databricks.com/ai-gateway/configure-ai-gateway-endpoints.html) | [Azure](https://learn.microsoft.com/en-us/azure/databricks/ai-gateway/configure-ai-gateway-endpoints) | [GCP](https://docs.databricks.com/gcp/ai-gateway/configure-ai-gateway-endpoints))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a64d57eb-2d80-41e7-afe4-915ea32d7abc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -U -qqqq openai langchain databricks-langchain\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2e489a5-c18d-46c6-80fd-94313e4408f3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.text(name=\"catalog\", defaultValue=\"bo_cheng_dnb_demos\", label=\"catalog\")\n",
    "dbutils.widgets.text(name=\"schema\", defaultValue=\"clio\", label=\"schema\")\n",
    "dbutils.widgets.text(name=\"secret_scope\", defaultValue=\"dbdemos\", label=\"secret_scope\")\n",
    "dbutils.widgets.text(\n",
    "    name=\"openai_api_key_value\", defaultValue=\"\", label=\"openai_api_key_value\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17864d02-0429-4689-8089-ff5599c7a46c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.sdk import WorkspaceClient\n",
    "\n",
    "w = WorkspaceClient()\n",
    "\n",
    "DATABRICKS_HOST = w.config.host\n",
    "\n",
    "secret_scope_name = dbutils.widgets.get(\"secret_scope\")\n",
    "\n",
    "# if needed create a secret scope\n",
    "if secret_scope_name != \"dbdemos\":\n",
    "    w.secrets.create_scope(scope=secret_scope_name)\n",
    "else:\n",
    "    print(f\"Using existing secret scope: {secret_scope_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a472c7e-2436-4bec-8693-580ae40a9d2c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# name of model serving endpoint\n",
    "ENDPOINT_NAME = \"gpt-4o\"\n",
    "\n",
    "# catalog and schema for inference tables\n",
    "CATALOG_NAME = dbutils.widgets.get(\"catalog\")\n",
    "SCHEMA_NAME = dbutils.widgets.get(\"schema\")\n",
    "\n",
    "# openai API key in Databricks Secrets\n",
    "SECRETS_SCOPE = dbutils.widgets.get(\"secret_scope\")\n",
    "SECRETS_KEY = \"openai_api_key\"\n",
    "\n",
    "# if you need to add an OpenAI API key, you can do so with:\n",
    "if dbutils.widgets.get(\"openai_api_key_value\") == \"\":\n",
    "    print(f\"no openai_api_key_value provided, using existing secret\")\n",
    "else:\n",
    "    w.secrets.put_secret(\n",
    "        scope=SECRETS_SCOPE,\n",
    "        key=SECRETS_KEY,\n",
    "        string_value=dbutils.widgets.get(\"openai_api_key_value\"),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f4a20f1-e22d-4c0d-a4fd-7137563e84b7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Create a model serving endpoint for OpenAI GPT-4o-Mini\n",
    "\n",
    "The following creates a model serving endpoint for GPT-4o Mini *without* AI Gateway enabled. First, you define a helper function for creating and updating the endpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d7b81e60-fa8d-4e98-b960-86bb66f5cecb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "def configure_endpoint(\n",
    "    name: str,\n",
    "    databricks_token: str,\n",
    "    config: dict,\n",
    "    host: str,\n",
    "    endpoint_path: Optional[str] = None,\n",
    "):\n",
    "    base_url = f\"{host}/api/2.0/serving-endpoints\"\n",
    "\n",
    "    if endpoint_path:\n",
    "        # Update operation\n",
    "        api_url = f\"{base_url}/{name}/{endpoint_path}\"\n",
    "        method = requests.put\n",
    "        operation = \"Updating\"\n",
    "    else:\n",
    "        # Create operation\n",
    "        api_url = base_url\n",
    "        method = requests.post\n",
    "        operation = \"Creating\"\n",
    "\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {databricks_token}\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    }\n",
    "\n",
    "    print(f\"{operation} endpoint...\")\n",
    "    response = method(api_url, headers=headers, json=config)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(\n",
    "            f\"Failed to {operation.lower()} endpoint. Status code: {response.status_code}\"\n",
    "        )\n",
    "        return response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b8dbae65-b1af-435d-bd50-36de4e13191d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Next, write a simple configuration to set up the endpoint. See [POST\n",
    "/api/2.0/serving-endpoints](https://docs.databricks.com/api/workspace/servingendpoints/create) for API details.\n",
    "\n",
    "* Please keep in mind this openai config is related to an example provided please change the `openai_config` to reflect your environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d1527cde-f9f9-4501-b7da-182bb9d0730b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "create_endpoint_request_data = {\n",
    "    \"name\": ENDPOINT_NAME,\n",
    "    \"config\": {\n",
    "        \"served_entities\": [\n",
    "            {\n",
    "                \"name\": \"gpt-4o\",\n",
    "                \"external_model\": {\n",
    "                    \"name\": \"gpt-4o\",\n",
    "                    \"provider\": \"openai\",\n",
    "                    \"task\": \"llm/v1/chat\",\n",
    "                    \"openai_config\": {\n",
    "                        \"openai_api_type\": \"azure\",\n",
    "                        \"openai_api_key\": f\"{{{{secrets/{SECRETS_SCOPE}/{SECRETS_KEY}}}}}\",\n",
    "                        \"openai_api_base\": \"https://doan-azure-openai.openai.azure.com\",\n",
    "                        \"openai_deployment_name\": \"gpt-4o\",\n",
    "                        \"openai_api_version\": \"2025-01-01-preview\",\n",
    "                    },\n",
    "                },\n",
    "            }\n",
    "        ],\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "40eea572-48d8-458b-b9ea-8f7a4453e2d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "tmp_token = w.tokens.create(\n",
    "    comment=f\"sdk-{time.time_ns()}\", lifetime_seconds=120\n",
    ").token_value\n",
    "\n",
    "configure_endpoint(\n",
    "    ENDPOINT_NAME, tmp_token, create_endpoint_request_data, DATABRICKS_HOST\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "79f82072-ac63-4913-ae8e-ce28e31f780e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "One of the immediate benefits of using OpenAI models (or models from other providers) using Databricks is that you can immediately query the model using the any of the following methods:\n",
    " - Databricks Python SDK\n",
    " - OpenAI Python client\n",
    " - REST API calls\n",
    " -  MLflow Deployments SDK\n",
    " - Databricks SQL `ai_query` function \n",
    "\n",
    "See the **Query foundation models and external models** article ([AWS](https://docs.databricks.com/en/machine-learning/model-serving/score-foundation-models.html) | [Azure](https://learn.microsoft.com/en-us/azure/databricks/machine-learning/model-serving/score-foundation-models) |  [GCP](https://docs.databricks.com/gcp/en/machine-learning/model-serving/score-foundation-models)).\n",
    "\n",
    "For example, you can use `ai_query` to query the model with Databricks SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a4c205c7-2dcd-423c-8368-ac256e507ca7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT\n",
    "  ai_query(\"gpt-4o\", \"What is a mixture of experts model?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a5b4121-b9d7-426a-9c16-c68dfa9df114",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Add an AI Gateway configuration\n",
    "\n",
    "After you set up a model serving endpoint, you can query the OpenAI model using any of the various querying methods accessible in Databricks.\n",
    "\n",
    "You can further enrich the model serving endpoint by enabling the Databricks Mosaic AI Gateway, which offers a variety of features for monitoring and managing your endpoint. These features include inference tables, guardrails, and rate limits, among other things.\n",
    "\n",
    "To start, the following is a simple configuration that enables inference tables for monitoring endpoint usage. Understanding how the endpoint is being used and how often, helps to determine what usage limits and guardrails are beneficial for your use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ffccf0b4-a80d-4326-bc75-b72a391d64e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "gateway_request_data = {\n",
    "    \"usage_tracking_config\": {\"enabled\": True},\n",
    "    \"inference_table_config\": {\n",
    "        \"enabled\": True,\n",
    "        \"catalog_name\": CATALOG_NAME,\n",
    "        \"schema_name\": SCHEMA_NAME,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a4dbf9e-fa01-4291-a0b8-7ad568851f30",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tmp_token = w.tokens.create(\n",
    "    comment=f\"sdk-{time.time_ns()}\", lifetime_seconds=120\n",
    ").token_value\n",
    "\n",
    "configure_endpoint(\n",
    "    ENDPOINT_NAME, tmp_token, gateway_request_data, DATABRICKS_HOST, \"ai-gateway\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 3054820919475749,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "external-models",
   "widgets": {
    "catalog": {
     "currentValue": "bo_cheng_dnb_demos",
     "nuid": "766c93e9-a034-4519-9dad-d8fa1d610c39",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "bo_cheng_dnb_demos",
      "label": "catalog",
      "name": "catalog",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "bo_cheng_dnb_demos",
      "label": "catalog",
      "name": "catalog",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "openai_api_key_value": {
     "currentValue": "",
     "nuid": "1142e386-c46e-4528-9289-63e76b30fbf8",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": "openai_api_key_value",
      "name": "openai_api_key_value",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": "openai_api_key_value",
      "name": "openai_api_key_value",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "schema": {
     "currentValue": "joby",
     "nuid": "95312432-7550-4657-8f67-eb5a0cf5ead1",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "clio",
      "label": "schema",
      "name": "schema",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "clio",
      "label": "schema",
      "name": "schema",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "secret_scope": {
     "currentValue": "dbdemos",
     "nuid": "7f0485ad-cdea-4056-aa82-bfa476153b80",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "dbdemos",
      "label": "secret_scope",
      "name": "secret_scope",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "dbdemos",
      "label": "secret_scope",
      "name": "secret_scope",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
